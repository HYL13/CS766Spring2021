{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of preparing the horses and zebra dataset\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from numpy import savez_compressed\n",
    " \n",
    "# load all images in a directory into memory\n",
    "def load_images(path, size=(256,256)):\n",
    "\tdata_list = list()\n",
    "\t# enumerate filenames in directory, assume all are images\n",
    "\tfor filename in listdir(path):\n",
    "\t\t# load and resize the image\n",
    "\t\tpixels = load_img(path + filename, target_size=size)\n",
    "\t\t# convert to numpy array\n",
    "\t\tpixels = img_to_array(pixels)\n",
    "\t\t# store\n",
    "\t\tdata_list.append(pixels)\n",
    "\treturn asarray(data_list)\n",
    " \n",
    "# dataset path\n",
    "path = 'maps/'\n",
    "# load dataset A\n",
    "dataA1 = load_images(path + 'trainA/')\n",
    "dataAB = load_images(path + 'testA/')\n",
    "dataA = vstack((dataA1, dataAB))\n",
    "print('Loaded dataA: ', dataA.shape)\n",
    "# load dataset B\n",
    "dataB1 = load_images(path + 'trainB/')\n",
    "dataB2 = load_images(path + 'testB/')\n",
    "dataB = vstack((dataB1, dataB2))\n",
    "print('Loaded dataB: ', dataB.shape)\n",
    "# save as compressed numpy array\n",
    "filename = 'maps_cycleGAN_256.npz'\n",
    "savez_compressed(filename, dataA, dataB)\n",
    "print('Saved dataset: ', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (2194, 256, 256, 3) (2194, 256, 256, 3)\n",
      "109700\n",
      "Step 1 took 87.44078373908997 seconds, dA[0.646,1.043] dB[1.032,0.894] g[21.288,20.048]\n",
      "Step 2 took 34.53094840049744 seconds, dA[0.901,1.098] dB[2.129,1.100] g[20.595,20.737]\n",
      "Step 3 took 40.792741775512695 seconds, dA[2.479,1.025] dB[2.697,1.274] g[21.055,20.368]\n",
      "Step 4 took 42.02374267578125 seconds, dA[2.059,2.355] dB[2.164,1.708] g[20.811,20.753]\n",
      "Step 5 took 36.45275044441223 seconds, dA[0.865,2.810] dB[1.477,0.905] g[18.970,20.097]\n",
      "Step 6 took 35.56735372543335 seconds, dA[1.338,3.049] dB[1.370,0.803] g[19.999,21.543]\n",
      "Step 7 took 36.05255651473999 seconds, dA[0.960,5.231] dB[1.224,1.354] g[20.192,22.406]\n",
      "Step 8 took 36.89954233169556 seconds, dA[0.950,5.256] dB[1.404,3.177] g[20.740,22.943]\n",
      "Step 9 took 36.20101761817932 seconds, dA[0.750,4.549] dB[2.013,1.968] g[21.252,21.614]\n",
      "Step 10 took 36.89896082878113 seconds, dA[0.661,3.563] dB[1.106,1.601] g[18.930,19.209]\n",
      "Step 11 took 34.02974987030029 seconds, dA[0.611,1.838] dB[0.765,0.790] g[18.407,18.043]\n",
      "Step 12 took 32.79043436050415 seconds, dA[0.908,0.929] dB[1.147,1.118] g[18.649,19.684]\n",
      "Step 13 took 32.201507329940796 seconds, dA[0.698,1.068] dB[0.917,1.507] g[17.668,16.400]\n",
      "Step 14 took 32.237359285354614 seconds, dA[0.635,0.861] dB[0.950,4.858] g[23.972,16.953]\n",
      "Step 15 took 32.64309096336365 seconds, dA[0.473,0.793] dB[1.366,6.111] g[30.321,16.572]\n",
      "Step 16 took 33.42763876914978 seconds, dA[0.687,0.777] dB[3.798,4.126] g[25.651,15.542]\n",
      "Step 17 took 33.2912483215332 seconds, dA[0.522,0.983] dB[6.625,1.795] g[20.314,16.716]\n",
      "Step 18 took 32.89815402030945 seconds, dA[0.704,1.027] dB[1.744,0.770] g[17.667,15.844]\n",
      "Step 19 took 32.87070345878601 seconds, dA[0.500,0.751] dB[0.765,0.889] g[18.120,15.564]\n",
      "Step 20 took 32.403106451034546 seconds, dA[0.524,0.691] dB[0.327,0.455] g[17.569,16.269]\n",
      "Step 21 took 32.531434059143066 seconds, dA[0.594,0.936] dB[0.671,0.456] g[16.626,15.965]\n",
      "Step 22 took 32.11129951477051 seconds, dA[0.582,0.884] dB[0.440,0.489] g[16.717,15.660]\n",
      "Step 23 took 33.0689218044281 seconds, dA[0.483,0.674] dB[0.929,0.413] g[15.770,14.693]\n",
      "Step 24 took 32.501710414886475 seconds, dA[0.511,0.837] dB[0.521,0.457] g[15.233,13.774]\n",
      "Step 25 took 33.207545042037964 seconds, dA[0.655,2.008] dB[0.716,0.558] g[13.501,13.995]\n",
      "Step 26 took 33.01354384422302 seconds, dA[0.921,0.707] dB[0.396,0.391] g[17.335,17.249]\n",
      "Step 27 took 32.46888852119446 seconds, dA[1.038,0.559] dB[0.327,0.522] g[17.116,16.369]\n",
      "Step 28 took 34.13152289390564 seconds, dA[0.528,0.772] dB[0.582,0.309] g[16.096,15.459]\n",
      "Step 29 took 32.61264634132385 seconds, dA[0.511,0.942] dB[0.405,0.360] g[16.809,16.046]\n",
      "Step 30 took 33.44770836830139 seconds, dA[0.406,0.713] dB[0.229,0.486] g[17.138,16.531]\n",
      "Step 31 took 31.71364426612854 seconds, dA[0.602,1.495] dB[0.756,0.478] g[15.570,16.012]\n",
      "Step 32 took 31.635531425476074 seconds, dA[0.947,1.272] dB[0.724,0.519] g[14.131,14.528]\n",
      "Step 33 took 31.777849912643433 seconds, dA[0.757,1.324] dB[0.261,0.558] g[15.483,15.053]\n",
      "Step 34 took 31.04283595085144 seconds, dA[0.611,1.516] dB[0.255,0.364] g[15.581,15.288]\n",
      "Step 35 took 31.05086588859558 seconds, dA[0.640,1.020] dB[0.466,0.388] g[15.063,14.261]\n",
      "Step 36 took 30.476081132888794 seconds, dA[0.616,2.773] dB[0.597,0.325] g[14.195,15.935]\n",
      "Step 37 took 30.994108200073242 seconds, dA[0.795,1.203] dB[0.243,0.463] g[14.954,14.151]\n",
      "Step 38 took 31.7044460773468 seconds, dA[1.154,0.833] dB[0.200,0.473] g[14.919,13.694]\n",
      "Step 39 took 31.176703691482544 seconds, dA[0.877,1.971] dB[0.228,0.374] g[15.042,15.127]\n",
      "Step 40 took 31.220112323760986 seconds, dA[0.630,1.220] dB[0.220,0.648] g[14.068,12.393]\n",
      "Step 41 took 31.67771339416504 seconds, dA[0.583,1.250] dB[0.216,0.402] g[15.161,14.257]\n",
      "Step 42 took 30.57599711418152 seconds, dA[0.388,0.923] dB[0.111,0.399] g[15.558,14.212]\n",
      "Step 43 took 31.1200008392334 seconds, dA[0.444,1.776] dB[0.240,0.244] g[15.630,15.274]\n",
      "Step 44 took 31.32002830505371 seconds, dA[0.492,0.731] dB[0.350,0.215] g[12.879,12.836]\n",
      "Step 45 took 31.263780117034912 seconds, dA[0.511,0.894] dB[0.250,0.297] g[13.471,13.257]\n",
      "Step 46 took 31.284798860549927 seconds, dA[0.418,0.462] dB[0.366,0.274] g[12.896,12.654]\n",
      "Step 47 took 30.951033353805542 seconds, dA[0.454,0.824] dB[0.463,0.175] g[14.027,12.630]\n",
      "Step 48 took 31.030486583709717 seconds, dA[0.418,0.683] dB[0.421,0.281] g[12.751,12.273]\n",
      "Step 49 took 31.023682594299316 seconds, dA[0.387,0.402] dB[0.238,0.285] g[14.724,13.254]\n",
      "Step 50 took 31.56631827354431 seconds, dA[0.339,0.406] dB[0.363,0.281] g[14.410,13.248]\n",
      "Step 51 took 31.890772819519043 seconds, dA[0.372,0.633] dB[0.176,0.215] g[15.323,14.120]\n",
      "Step 52 took 31.014564037322998 seconds, dA[0.263,0.821] dB[0.326,0.156] g[14.401,14.901]\n",
      "Step 53 took 31.184966325759888 seconds, dA[0.454,0.366] dB[0.235,0.264] g[14.623,13.505]\n",
      "Step 54 took 30.85060977935791 seconds, dA[0.506,0.541] dB[0.212,0.255] g[14.611,13.674]\n",
      "Step 55 took 31.370286226272583 seconds, dA[0.399,0.625] dB[0.156,0.164] g[14.830,13.356]\n",
      "Step 56 took 31.39259147644043 seconds, dA[0.399,0.850] dB[0.343,0.124] g[12.127,11.974]\n",
      "Step 57 took 31.01166868209839 seconds, dA[0.346,0.771] dB[0.314,0.218] g[14.111,13.166]\n",
      "Step 58 took 31.08765411376953 seconds, dA[0.427,0.656] dB[0.135,0.199] g[15.525,15.304]\n",
      "Step 59 took 31.170618772506714 seconds, dA[0.252,0.574] dB[0.289,0.209] g[15.174,15.466]\n",
      "Step 60 took 30.97890067100525 seconds, dA[0.281,0.321] dB[0.224,0.134] g[13.337,13.326]\n",
      "Step 61 took 31.092723608016968 seconds, dA[0.430,0.730] dB[1.124,0.289] g[13.546,12.977]\n",
      "Step 62 took 31.098795413970947 seconds, dA[0.403,0.994] dB[0.584,0.301] g[12.655,12.476]\n",
      "Step 63 took 30.964919328689575 seconds, dA[0.411,0.423] dB[0.293,0.142] g[14.397,12.701]\n",
      "Step 64 took 30.984007835388184 seconds, dA[0.362,0.679] dB[0.243,0.155] g[14.918,13.737]\n",
      "Step 65 took 30.970214366912842 seconds, dA[0.329,0.307] dB[0.360,0.152] g[12.206,11.798]\n",
      "Step 66 took 31.69524335861206 seconds, dA[0.314,0.261] dB[0.184,0.229] g[12.490,11.751]\n",
      "Step 67 took 31.521095275878906 seconds, dA[0.320,0.715] dB[0.154,0.122] g[15.428,14.102]\n",
      "Step 68 took 30.925882577896118 seconds, dA[0.294,0.395] dB[0.215,0.118] g[15.001,13.612]\n",
      "Step 69 took 30.425000190734863 seconds, dA[0.388,0.440] dB[0.135,0.284] g[14.611,12.917]\n",
      "Step 70 took 30.806914567947388 seconds, dA[0.342,0.638] dB[0.145,0.216] g[11.614,13.054]\n",
      "Step 71 took 30.919933319091797 seconds, dA[0.398,0.414] dB[0.126,0.166] g[14.345,13.005]\n",
      "Step 72 took 30.698770999908447 seconds, dA[0.364,0.608] dB[0.087,0.141] g[12.431,11.753]\n",
      "Step 73 took 30.440096616744995 seconds, dA[0.363,0.350] dB[0.077,0.130] g[14.563,12.994]\n",
      "Step 74 took 31.561851024627686 seconds, dA[0.327,0.538] dB[0.161,0.139] g[13.723,12.026]\n",
      "Step 75 took 31.359493017196655 seconds, dA[0.321,0.685] dB[0.115,0.214] g[14.197,12.585]\n",
      "Step 76 took 30.62513780593872 seconds, dA[0.515,0.402] dB[0.092,0.262] g[13.308,11.344]\n",
      "Step 77 took 30.750300884246826 seconds, dA[0.289,0.333] dB[0.108,0.267] g[17.218,16.916]\n",
      "Step 78 took 31.35800838470459 seconds, dA[0.573,0.360] dB[0.105,0.247] g[14.560,13.120]\n",
      "Step 79 took 31.147979974746704 seconds, dA[0.411,0.844] dB[0.136,0.240] g[15.186,14.574]\n",
      "Step 80 took 30.824865341186523 seconds, dA[0.327,0.438] dB[0.162,0.250] g[13.587,12.321]\n",
      "Step 81 took 30.95971655845642 seconds, dA[0.336,0.750] dB[0.086,0.149] g[14.553,14.263]\n",
      "Step 82 took 31.072877168655396 seconds, dA[0.366,0.507] dB[0.164,0.142] g[13.645,12.701]\n",
      "Step 83 took 31.242233753204346 seconds, dA[0.619,0.285] dB[0.086,0.129] g[11.660,11.289]\n",
      "Step 84 took 30.80187749862671 seconds, dA[0.311,0.432] dB[0.108,0.121] g[11.747,10.847]\n",
      "Step 85 took 30.652268171310425 seconds, dA[0.218,0.555] dB[0.133,0.062] g[14.227,12.439]\n",
      "Step 86 took 30.97263526916504 seconds, dA[0.381,0.285] dB[0.059,0.116] g[14.018,12.382]\n",
      "Step 87 took 30.694151163101196 seconds, dA[0.251,0.197] dB[0.075,0.067] g[14.794,13.210]\n",
      "Step 88 took 30.998746395111084 seconds, dA[0.231,0.308] dB[0.176,0.128] g[10.956,10.134]\n",
      "Step 89 took 30.960289239883423 seconds, dA[0.205,0.196] dB[0.144,0.096] g[13.213,12.194]\n",
      "Step 90 took 31.163013219833374 seconds, dA[0.210,0.176] dB[0.093,0.062] g[15.281,14.415]\n",
      "Step 91 took 31.707411527633667 seconds, dA[0.245,0.282] dB[0.071,0.082] g[14.193,12.409]\n",
      "Step 92 took 30.867568254470825 seconds, dA[0.298,0.149] dB[0.087,0.203] g[14.543,12.990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 93 took 31.847293853759766 seconds, dA[0.191,0.244] dB[0.062,0.194] g[14.287,12.371]\n",
      "Step 94 took 30.430177450180054 seconds, dA[0.251,0.287] dB[0.079,0.161] g[14.470,12.747]\n",
      "Step 95 took 30.610000133514404 seconds, dA[0.248,0.298] dB[0.099,0.122] g[14.526,12.916]\n",
      "Step 96 took 30.509997606277466 seconds, dA[0.178,0.153] dB[0.215,0.125] g[13.118,12.467]\n",
      "Step 97 took 30.416001558303833 seconds, dA[0.220,0.285] dB[0.111,0.197] g[11.630,11.065]\n",
      "Step 98 took 30.343268632888794 seconds, dA[0.221,0.277] dB[0.248,0.056] g[13.652,11.712]\n",
      "Step 99 took 30.22508215904236 seconds, dA[0.228,0.190] dB[0.098,0.118] g[13.226,11.318]\n",
      "Step 100 took 30.386000871658325 seconds, dA[0.140,0.417] dB[0.082,0.093] g[15.065,14.292]\n",
      ">Saved: g_model_AtoB_000100.h5 and g_model_BtoA_000100.h5\n",
      "Step 101 took 30.18367338180542 seconds, dA[0.299,0.165] dB[0.066,0.071] g[13.628,12.064]\n",
      "Step 102 took 30.999128818511963 seconds, dA[0.149,0.105] dB[0.109,0.097] g[11.057,9.674]\n",
      "Step 103 took 30.560001373291016 seconds, dA[0.110,0.164] dB[0.094,0.135] g[12.033,10.098]\n",
      "Step 104 took 30.548998594284058 seconds, dA[0.160,0.220] dB[0.072,0.075] g[12.722,10.330]\n",
      "Step 105 took 30.035999298095703 seconds, dA[0.140,0.186] dB[0.073,0.105] g[14.505,12.837]\n",
      "Step 106 took 30.8370578289032 seconds, dA[0.344,0.053] dB[0.084,0.058] g[12.788,11.631]\n",
      "Step 107 took 31.078603982925415 seconds, dA[0.161,0.272] dB[0.107,0.133] g[14.508,13.599]\n",
      "Step 108 took 30.71814203262329 seconds, dA[0.172,0.183] dB[0.119,0.046] g[13.690,12.226]\n",
      "Step 109 took 31.898348808288574 seconds, dA[0.215,0.114] dB[0.092,0.116] g[14.745,13.700]\n",
      "Step 110 took 30.900375843048096 seconds, dA[0.255,0.208] dB[0.064,0.254] g[13.901,12.471]\n",
      "Step 111 took 32.13902497291565 seconds, dA[0.142,0.215] dB[0.089,0.088] g[15.530,15.024]\n",
      "Step 112 took 31.696114778518677 seconds, dA[0.178,0.100] dB[0.101,0.067] g[13.694,12.346]\n",
      "Step 113 took 30.983136653900146 seconds, dA[0.206,0.201] dB[0.132,0.115] g[14.318,13.290]\n",
      "Step 114 took 31.232658863067627 seconds, dA[0.089,0.101] dB[0.139,0.077] g[13.392,12.614]\n",
      "Step 115 took 31.592188835144043 seconds, dA[0.187,0.388] dB[0.085,0.087] g[13.415,11.851]\n",
      "Step 116 took 31.191635131835938 seconds, dA[0.153,0.131] dB[0.159,0.061] g[12.845,12.116]\n",
      "Step 117 took 30.897567987442017 seconds, dA[0.240,0.147] dB[0.086,0.101] g[11.910,11.002]\n",
      "Step 118 took 30.229106664657593 seconds, dA[0.165,0.343] dB[0.046,0.129] g[13.671,11.750]\n",
      "Step 119 took 30.18899917602539 seconds, dA[0.196,0.158] dB[0.050,0.063] g[13.518,12.267]\n",
      "Step 120 took 30.27700161933899 seconds, dA[0.274,0.120] dB[0.068,0.068] g[11.829,11.875]\n",
      "Step 121 took 30.244835138320923 seconds, dA[0.201,0.075] dB[0.080,0.031] g[13.724,12.127]\n",
      "Step 122 took 30.327001333236694 seconds, dA[0.209,0.042] dB[0.092,0.130] g[12.290,12.025]\n",
      "Step 123 took 30.234999418258667 seconds, dA[0.229,0.192] dB[0.056,0.144] g[13.677,12.853]\n",
      "Step 124 took 30.27599811553955 seconds, dA[0.258,0.181] dB[0.077,0.161] g[13.826,12.495]\n",
      "Step 125 took 31.226881980895996 seconds, dA[0.160,0.204] dB[0.107,0.167] g[15.121,14.022]\n",
      "Step 126 took 31.76833176612854 seconds, dA[0.149,0.116] dB[0.173,0.104] g[14.596,13.003]\n",
      "Step 127 took 31.88035750389099 seconds, dA[0.250,0.097] dB[0.194,0.096] g[13.088,11.991]\n",
      "Step 128 took 30.724689245224 seconds, dA[0.147,0.320] dB[0.040,0.082] g[14.643,13.565]\n",
      "Step 129 took 30.268468141555786 seconds, dA[0.158,0.056] dB[0.088,0.079] g[13.302,13.413]\n",
      "Step 130 took 30.51499891281128 seconds, dA[0.350,0.039] dB[0.143,0.059] g[12.573,11.576]\n",
      "Step 131 took 31.238521099090576 seconds, dA[0.243,0.236] dB[0.067,0.073] g[13.055,11.274]\n",
      "Step 132 took 30.77453923225403 seconds, dA[0.129,0.139] dB[0.096,0.058] g[12.561,11.473]\n",
      "Step 133 took 30.861818075180054 seconds, dA[0.087,0.072] dB[0.100,0.072] g[14.041,13.042]\n",
      "Step 134 took 30.203407049179077 seconds, dA[0.321,0.104] dB[0.062,0.076] g[13.615,12.302]\n",
      "Step 135 took 30.335002899169922 seconds, dA[0.158,0.048] dB[0.051,0.054] g[13.384,11.505]\n",
      "Step 136 took 31.022602081298828 seconds, dA[0.072,0.090] dB[0.062,0.033] g[13.980,12.172]\n",
      "Step 137 took 31.21329617500305 seconds, dA[0.122,0.080] dB[0.041,0.070] g[14.935,13.811]\n",
      "Step 138 took 31.447700023651123 seconds, dA[0.403,0.080] dB[0.072,0.042] g[11.898,10.536]\n",
      "Step 139 took 30.926884651184082 seconds, dA[0.132,0.087] dB[0.093,0.058] g[10.476,9.819]\n",
      "Step 140 took 30.97265911102295 seconds, dA[0.107,0.042] dB[0.096,0.106] g[14.110,12.346]\n",
      "Step 141 took 31.02440333366394 seconds, dA[0.073,0.201] dB[0.094,0.062] g[14.910,13.621]\n",
      "Step 142 took 31.104764699935913 seconds, dA[0.217,0.045] dB[0.130,0.062] g[13.331,11.511]\n",
      "Step 143 took 30.805968761444092 seconds, dA[0.309,0.099] dB[0.106,0.038] g[12.750,10.824]\n",
      "Step 144 took 31.424172163009644 seconds, dA[0.126,0.122] dB[0.086,0.168] g[14.023,12.761]\n",
      "Step 145 took 30.923229217529297 seconds, dA[0.148,0.158] dB[0.067,0.075] g[14.248,12.234]\n",
      "Step 146 took 30.927666902542114 seconds, dA[0.126,0.035] dB[0.085,0.064] g[14.050,12.131]\n",
      "Step 147 took 30.90724802017212 seconds, dA[0.110,0.120] dB[0.083,0.083] g[13.547,12.254]\n",
      "Step 148 took 30.88341498374939 seconds, dA[0.294,0.115] dB[0.079,0.072] g[12.966,11.319]\n",
      "Step 149 took 31.65364384651184 seconds, dA[0.179,0.204] dB[0.074,0.115] g[13.872,11.864]\n",
      "Step 150 took 31.208377599716187 seconds, dA[0.173,0.103] dB[0.057,0.045] g[12.729,11.421]\n",
      "Step 151 took 32.36153793334961 seconds, dA[0.153,0.310] dB[0.072,0.079] g[12.054,11.558]\n"
     ]
    }
   ],
   "source": [
    "# example of training a cyclegan on the horse2zebra dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from random import random\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    # define model\n",
    "    model = Model(in_image, patch_out)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
    "    return model\n",
    "\n",
    "# generator a resnet block\n",
    "def resnet_block(n_filters, input_layer):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # first layer convolutional layer\n",
    "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # second convolutional layer\n",
    "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    # concatenate merge channel-wise with input layer\n",
    "    g = Concatenate()([g, input_layer])\n",
    "    return g\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape, n_resnet=9):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # c7s1-64\n",
    "    g = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d128\n",
    "    g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d256\n",
    "    g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # R256\n",
    "    for _ in range(n_resnet):\n",
    "        g = resnet_block(256, g)\n",
    "    # u128\n",
    "    g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # u64\n",
    "    g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # c7s1-3\n",
    "    g = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model\n",
    "\n",
    "# define a composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    # ensure the model we're updating is trainable\n",
    "    g_model_1.trainable = True\n",
    "    # mark discriminator as not trainable\n",
    "    d_model.trainable = False\n",
    "    # mark other generator model as not trainable\n",
    "    g_model_2.trainable = False\n",
    "    # discriminator element\n",
    "    input_gen = Input(shape=image_shape)\n",
    "    gen1_out = g_model_1(input_gen)\n",
    "    output_d = d_model(gen1_out)\n",
    "    # identity element\n",
    "    input_id = Input(shape=image_shape)\n",
    "    output_id = g_model_1(input_id)\n",
    "    # forward cycle\n",
    "    output_f = g_model_2(gen1_out)\n",
    "    # backward cycle\n",
    "    gen2_out = g_model_2(input_id)\n",
    "    output_b = g_model_1(gen2_out)\n",
    "    # define model graph\n",
    "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "    # define optimization algorithm configuration\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    # compile model with weighting of least squares loss and L1 loss\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "    # load the dataset\n",
    "    data = load(filename)\n",
    "    # unpack arrays\n",
    "    X1, X2 = data['arr_0'], data['arr_1']\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X1 = (X1 - 127.5) / 127.5\n",
    "    X2 = (X2 - 127.5) / 127.5\n",
    "    return [X1, X2]\n",
    "\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, dataset, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(dataset)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "# save the generator models to file\n",
    "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
    "    # save the first generator model\n",
    "    filename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
    "    g_model_AtoB.save(filename1)\n",
    "    # save the second generator model\n",
    "    filename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n",
    "    g_model_BtoA.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
    "    # select a sample of input images\n",
    "    X_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
    "    # generate translated images\n",
    "    X_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_in = (X_in + 1) / 2.0\n",
    "    X_out = (X_out + 1) / 2.0\n",
    "    # plot real images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(2, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_in[i])\n",
    "    # plot translated image\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_out[i])\n",
    "    # save plot to file\n",
    "    filename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "\n",
    "# update image pool for fake images\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            # use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # replace an existing image and use replaced image\n",
    "            ix = randint(0, len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return asarray(selected)\n",
    "\n",
    "# train cyclegan models\n",
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
    "    # define properties of the training run\n",
    "    n_epochs, n_batch, = 50, 1\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = d_model_A.output_shape[1]\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # prepare image pool for fakes\n",
    "    poolA, poolB = list(), list()\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    print(n_steps)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        import time\n",
    "        T1 = time.time()\n",
    "        # select a batch of real samples\n",
    "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "        # update fakes from pool\n",
    "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "        # update generator B->A via adversarial and cycle loss\n",
    "        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        # update discriminator for A -> [real/fake]\n",
    "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "        # update generator A->B via adversarial and cycle loss\n",
    "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        # update discriminator for B -> [real/fake]\n",
    "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "        # summarize performance\n",
    "        print('Step %d took %s seconds, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1,time.time()-T1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
    "        # evaluate the model performance every so often\n",
    "        if (i+1) % 100 == 0:\n",
    "            # plot A->B translation\n",
    "            summarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n",
    "            # plot B->A translation\n",
    "            summarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n",
    "            # save the models\n",
    "            save_models(i, g_model_AtoB, g_model_BtoA)\n",
    "\n",
    "# load image data\n",
    "dataset = load_real_samples('maps_cycleGAN_256.npz')\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
